# people_tracking
В ходе изучения  фреймфорка FairMOT  было выполнено:

**1. Разметка датасета для детекции совместно с остальными группами изучавшими встроенные трекеры YOLO и сторонние трекеры.**

**2. Конвертация лейблов формата YOLO** - 0 0.616093 0.552211 0.234644 0.414005 где 0 - class_id 0.616093 - center_x 0.552211 - center_y 0.234644 - width 0.414005 - height **в формат FairMOT** frame, id, bb_left, bb_top, bb_width, bb_height, conf, class, Visibility где: 

frame – порядковый номер фрейма.

id - Идентификатор рамки (-1), id детектируемого объекта (Каждая траиектория объекта идентифицируется уникальным идентификатором (-1 для обнаружения).

bb_left -  Координаты x (это center_x YOLO * размер изображения х).

bb_top -  Координаты y (это center_y YOLO * размер изображения у).

bb_width -  Ширина (это width YOLO * ширину зображения / 2).

bb_height -  Высота (это height YOLO * высоту зображения / 2).

conf -  Область уверенности (0-1) (1) другими словами точность детектируемого объекта.

class -  класс объекта как в YOLO class_id.

Visibility -  Видимость или коэфициент видимости от 0 до 1, который указывает, какая часть этого объекта видна. Может быть из-за окклюзии или обрезки границ изображения.

  После конвертации и ряда эксперементов на базовом репозитории https://github.com/NS19972/FairMOT было принято решение переразметки т.к. имеющийся датасет не показывал видимых результатов в отслеживании объектов.

**3. Было выполнено разбиение тренировочного видео с частотой до 30 кадров в секунду (частота обработки видео FairMOTом 26-30 кадров в сек), в ручную убраны пустые кадры и так же вручную поделены на тренировочную и валидационную выборки, идея заключалась в разметке трекингом (одного и того же идентификатора рамки) с помощью сервиса для разметки CVAT. Было размеченно порядка 9-10 тыс фреймов с общим количеством уникальных идентификаторов рамок = 297 (7 классов, Человек, Человек в каске, Человек в жилете, Человек в каске в жилете, Охранник, Каска, Жилет).**

**4. Формирование лейблов для обучения происходит с помощью файла gen_labels_mot16_cvat.py на основании gt.txt (выгруженный формат оннотаций MOT 1.1 с сервиса CVAT) и аннотаций в формате .xml (выгруженных с сервиса CVAT в формате CVAT for images 1.1)**

**5. Были выполнены эксперементы с различными архитектурами базового репозитория** https://github.com/NS19972/FairMOT (без новой разметки) и **второстепенного репозитория с детектором YOLOv4** https://github.com/CaptainEven/YOLOV4_MCMOT на новой разметке.

**6. Были изменены базовые файлы для генерации лейблов для последующего обучения сети (gen_labels_mot16_cvat.py).**

**7. Для обучения был добавлен файл запуска обучения train_val.py с выводом валидационной ошибки (в исходном такой функции прописано не было)**

При запуске последнего блокнота обучения не забудьте поменять пути сохранения моделей на гугл диск в файле запуска обучения 
train_val.py

Большая часть и финальные (с трекинговой разметкой) эксперементы проводились на локальной машине. До обучение сети имеет эфективность в 10-20% по времени, что бы достич предыдущих результатов обучаемой модели. Поэтому вариант до обучения весьма затягивается.

**Так же стоит отметить две отправные точки обучения:**

1. При обучении без учета валидации, ошибка по всем параметрам постоянно снижается, спустя 50 эпох, понимажается шаг обучения что способствует увеличению понижения ошибки с каждой эпохой (параметр настраивается).

2. При обучении с валидацией, валидация уходит в переобучение с 25-35 эпохи, при обучении разных архитектур.

**Выводы:** на данный момент проводится обучение различных архитектур с репозитория https://github.com/CaptainEven/YOLOV4_MCMOT с выводом валидационной ошибки, но складывается впечатление что трейн и вал обучаются отдельно друг от друга, т.е. валидация не является проверкой трейна при обучении. Дальнейшими вариантами для обучения (как предпологалось ранее), могут стать, обучение всего датасета помещенного в трейн на максимальном количеством эпох (1000 и более), с отслеживанием с помощью предикта качества трекинга, и возмыжным увеличением датасета (непосредственно сцен трекинга, более 297).